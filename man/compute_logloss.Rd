% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compute_logloss.R
\name{compute_logloss}
\alias{compute_logloss}
\title{Compare Cross-Fitting Model Log Losses Across Learners}
\usage{
compute_logloss(K, Y, A, X, S, W, foldid, R)
}
\arguments{
\item{K}{Integer. Number of cross-fitting folds.}

\item{Y}{Numeric or factor vector. Outcome variable (binary); NAs allowed for unlabelled data.}

\item{A}{Numeric or binary vector. Treatment indicator; not used in this function but passed for consistency.}

\item{X}{Matrix or data frame. Covariates used by the models.}

\item{S}{Matrix or data frame. Additional features (not used here but passed for interface consistency).}

\item{W}{Matrix or data frame. Combination of X and S (not used in this function).}

\item{foldid}{Integer vector. Fold assignments for cross-fitting.}

\item{R}{Binary vector. 1 for labelled samples (used to filter training data), 0 for unlabelled.}
}
\value{
A list containing:
\describe{
\item{logloss_combined}{A data frame with columns: \code{Model}, \code{Tuning_Parameter}, and \code{LogLoss}. One row per tuning round for each model.}
\item{logloss_xgboost_log_losses}{Vector of log loss values for each tuning round from xgboost.}
\item{logloss_bspline_log_losses}{Vector of log loss values for each tuning round from bspline.}
\item{logloss_randomforest_log_losses}{Vector of log loss values for each tuning round from randomforest.}
\item{all_tuning_params}{Named list of tuning parameter names for each model.}
}
}
\description{
Runs the \code{cf} function using three different learning algorithms (\code{xgboost}, \code{bspline}, and \code{randomforest}),
and compiles the resulting log loss metrics across tuning rounds into a unified summary.
}
\details{
This function is helpful for comparing the cross-validated performance (in terms of log loss) of different predictive models
under a semi-supervised setting. Internally, it calls the \code{cf} function for each model type and aggregates the results.
}
